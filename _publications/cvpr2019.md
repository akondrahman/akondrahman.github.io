---
title: "Blockchain Enabled AI Marketplace: The Price You Pay For Trust"
collection: publications
permalink: /publication/cvpr2019
date: 2019-07-05
venue: 'International Workshop of Blockchain Meets Computer Vision and Artificial Intelligence, co-located with Conference on Computer Vision and Pattern Recognition (CVPR)' 
paperurl: 'https://openaccess.thecvf.com/content_CVPRW_2019/papers/BCMCVAI/Sarpatwar_Blockchain_Enabled_AI_Marketplace_The_Price_You_Pay_for_Trust_CVPRW_2019_paper.pdf'
authors: Kanthi Sarpatwar, Venkata Sitaramagiridharganesh Ganapavarapu, Karthikeyan Shanmugam, Akond Rahman, and Roman Vaculin
year: 2019
index: 26
--- 
There has been a considerable amount of interest in exploring blockchain technologies for enabling marketplaces
of different kinds. In this work, we provide a blockchain implementation that enables an 'AI marketplace': a platform where consumers and data providers can transact data and/or models and derive value. Preserving privacy and trust during these transactions is a paramount concern. As an enabling use case, we consider a transfer learning setting. In this setting, a consumer entity wants to acquire a large training set from different private data providers that matches a small validation dataset provided by the consumer. Data providers expect a fair value for their contribution and the consumer also wants to maximize its benefit. We implement a distributed protocol on a blockchain that provides guarantees on privacy and consumerâ€™s benefit. We also demonstrate that our blockchain implementation plays a crucial role in addressing the issue of fair value attribution and privacy in a trustable way.

We consider three different designs for a blockchain implementation that trades off trust requirements on different entities and the overhead in terms of time taken for completion of the task. The first design provides no trust guarantees. The second one guarantees trust with respect to other participants if the platform is trustworthy. The third one guarantees complete trust with no requirements. Our experiments show that the performance in the second and third cases, with partial/complete trust guarantees, degrade by roughly 2X and 5X respectively, compared to the baseline with no trust guarantees.